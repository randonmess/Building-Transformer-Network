# Building-Transformer-Network
Using TF Keras to build the Transformer Network architecture

## Objectives
* Create positional encodings to capture sequential relationships in data
* Calculate scaled dot-product self-attention with word embeddings
* Implement masked multi-head attention
* Build and train a Transformer model
